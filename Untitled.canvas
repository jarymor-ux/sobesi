{
	"nodes":[
		{"id":"8383724afe762f16","x":-480,"y":-980,"width":840,"height":2440,"type":"text","text":"**М.Видео**\n\n_Golang Developer_\n\n**Ноябрь 2021 — Май 2023**\n\n### Проект\n\nРаботал над backend-сервисами для онлайн-платформы управления заказами. Система была highload, обрабатывала тысячи заказов в сутки с пиковыми нагрузками до 20 000 запросов в день. Основная цель — обеспечение надежности и масштабируемости платформы.\n\n### Команда\n\nВ команде было 8 backend-разработчиков, 4 frontend-разработчика, 3 тестировщика, DevOps-инженер и тимлид. Работа велась в распределенной команде по Scrum, с двухнедельными спринтами, ежедневными дейли-митингами и ретроспективами в конце спринта.\n\n### Основные технологии\n\n- **Базы данных и кеши**: PostgreSQL, Redis, ClickHouse\n    \n- **Очереди**: Kafka, RabbitMQ\n    \n- **API**: REST, gRPC\n    \n- **Контейнеризация и оркестрация**: Docker, Kubernetes\n    \n- **Мониторинг и логирование**: OpenTelemetry, ELK\n    \n- **CI/CD**: GitLab CI/CD\n    \n- **Инфраструктура**: Terraform\n    \n\n### Вклад и достижения\n\n- Разрабатывал backend-сервисы для управления заказами, обеспечивая их надежную работу под высокой нагрузкой.\n    \n- Интегрировал платежные шлюзы и системы лояльности с использованием gRPC и RabbitMQ, что увеличило надежность обработки платежей на 30%.\n    \n- Разработал API для управления программой лояльности, что позволило внедрить персонализированные скидки и бонусы для клиентов, увеличив конверсию использования бонусов на 15%.\n    \n- Внедрил систему мониторинга бизнес-метрик с OpenTelemetry и ELK, что сократило время диагностики сбоев на 40%.\n    \n- Автоматизировал CI/CD пайплайн для деплоя обновлений, сократив время выхода новых релизов с 1 недели до 2 дней.\n    \n\n### Сложные и интересные задачи\n\n- Оптимизировал SQL-запросы в PostgreSQL, что снизило среднее время ответа API с 200 мс до 80 мс.\n    \n- Реализовал механизм дедупликации событий в Kafka, устранив дублирующие сообщения и снизив нагрузку на базу данных на 25%.\n    \n- Настроил балансировку нагрузки на API с помощью Envoy, что позволило повысить отказоустойчивость системы.\n\n\n\n\n### Факап на работе и вынесенный урок (М.Видео)\n\n**Ситуация**  \nВо время работы в **М.Видео** мне поручили оптимизировать обработку заказов в очереди Kafka. Одна из задач заключалась в снижении нагрузки на базу данных, так как в пиковые часы (например, во время распродаж) количество заказов увеличивалось в несколько раз, и сервис начинал тормозить.\n\nЯ решил добавить механизм **batch-пакетов** — вместо того чтобы писать в базу каждую операцию отдельно, заказы собирались в пакеты и записывались одним большим батчем, что должно было снизить нагрузку на PostgreSQL. Локальные тесты показали хороший результат, и я задеплоил изменения в прод.\n\n**Что пошло не так?**  \nСпустя час после развертывания начали поступать жалобы: некоторые заказы зависали в статусе «Ожидание оплаты», а клиенты не получали подтверждения. Оказалось, что в реализации батч-записи я не учел один важный момент: если один из заказов в батче был некорректным (например, из-за ошибки в данных), весь батч откатывался.\n\nИз-за этого сотни заказов не сохранялись, а клиенты не получали подтверждения. Кульминацией стала ночь, когда нагрузка резко выросла из-за акции, и тысячи заказов просто зависли. Это привело к финансовым потерям и большому количеству жалоб в поддержку.\n\n**Как исправили?**\n\n1. **Откатили изменения** — вернули старый механизм записи, чтобы остановить сбои.\n2. **Проанализировали проблему** — обнаружили, что из-за отказа одного заказа откатывался весь батч.\n3. **Изменили стратегию обработки ошибок** — теперь при ошибке в одном заказе батч продолжал выполняться, а проблемные заказы записывались в отдельную очередь на разбирательство.\n4. **Добавили автоматический ретрай** — если запись не удалась из-за временной ошибки (например, блокировки таблицы), заказ повторялся с экспоненциальной задержкой.\n5. **Настроили алерты и мониторинг** — теперь если заказы зависали в ожидании, система отправляла предупреждения в Slack, и команда могла быстро реагировать.\n\n**Вывод и урок**\n\n- **Никогда не деплоить критические изменения без полной стратегии отката и мониторинга.**\n- **При работе с батч-обработкой важно учитывать частичный отказ.** Нужно предусмотреть, что один ошибочный элемент не должен ломать весь процесс.\n- **Тестирование на реальных данных важно.** Локальные тесты — это хорошо, но в проде могут всплыть неожиданные сценарии.\n\nПосле исправления логики нам удалось не только предотвратить подобные ошибки в будущем, но и снизить нагрузку на базу на 25%, а время обработки заказов уменьшилось в среднем с 500 мс до 200 мс."},
		{"id":"f07f5b45a3071b51","x":420,"y":-980,"width":1240,"height":2480,"type":"text","text":"**FIX Price**\n\n_Golang Developer_\n\n**Июнь 2023 — Настоящее время**\n\n### Проект\n\nРазрабатываю highload сервисы для автоматизации процессов ценообразования и управления акциями в сети магазинов. Система ежедневно обрабатывает 5 000 — 10 000 событий, в пиковые дни нагрузка достигает 20 000 событий.\n\n### Команда\n\nВ команде 6 backend-разработчиков, 3 аналитика, 2 DevOps-инженера, 2 тестировщика и тимлид. Работаем по Scrum, с двухнедельными спринтами, ежедневными стендапами и оценкой задач методом покера.\n\n### Основные технологии\n\n- **Базы данных и кеши**: PostgreSQL, Redis, ClickHouse\n    \n- **Очереди**: Kafka, NATS, RabbitMQ\n    \n- **API**: REST, gRPC, WebSockets\n    \n- **Контейнеризация и оркестрация**: Docker, Kubernetes\n    \n- **Мониторинг и логирование**: OpenTelemetry, ELK\n    \n- **CI/CD**: GitLab CI/CD\n    \n- **Сервис-дискавери**: Consul\n    \n\n### Вклад и достижения\n\n- **Разработал алгоритмы динамического ценообразования на основе ClickHouse**:\n    \n    1. Проанализировал текущие модели ценообразования и выявил узкие места.\n        \n    2. Разработал алгоритм, учитывающий спрос, сезонность и конкурентные цены.\n        \n    3. Настроил ETL-процессы для агрегации данных о продажах и динамике цен.\n        \n    4. Оптимизировал запросы в ClickHouse, сократив время обработки на 60%.\n        \n    5. Итог: алгоритм позволил автоматически корректировать цены, повысив маржинальность на 8%.\n        \n- **Реализовал сервис прогнозирования продаж с использованием Kafka и NATS**:\n    \n    1. Проанализировал исторические данные о продажах.\n        \n    2. Реализовал механизм потоковой обработки данных с Kafka и NATS.\n        \n    3. Обучил модель прогнозирования спроса с учетом сезонности и трендов.\n        \n    4. Внедрил автоматизированные оповещения для отдела закупок.\n        \n    5. Итог: улучшено управление закупками, снижены избыточные складские остатки на 12%.\n        \n- **Разработал REST API для интеграции с поставщиками**:\n    \n    1. Определил основные бизнес-процессы и ключевые требования к API.\n        \n    2. Реализовал API с валидацией входных данных и аутентификацией через OAuth2.\n        \n    3. Настроил мониторинг и трассировку запросов через OpenTelemetry.\n        \n    4. Автоматизировал процесс обработки заявок на новые поставки.\n        \n    5. Итог: ускорена обработка заявок на 25%.\n        \n- **Настроил систему мониторинга логистических цепочек с WebSockets**:\n    \n    1. Выявил проблемы в существующей системе логистики.\n        \n    2. Разработал WebSockets-сервис для отслеживания перемещения товаров в реальном времени.\n        \n    3. Внедрил автоматизированные оповещения при задержках в поставках.\n        \n    4. Настроил дашборды с метриками перемещения грузов.\n        \n    5. Итог: сократили время обработки логистических событий на 30%.\n        \n- **Внедрил систему отчетности для маркетинга и продаж с использованием ELK**:\n    \n    1. Систематизировал потребности маркетингового отдела в аналитике.\n        \n    2. Настроил сбор данных через Logstash и индексацию в Elasticsearch.\n        \n    3. Создал дашборды в Kibana с визуализацией ключевых метрик.\n        \n    4. Автоматизировал формирование отчетов по продажам и акциям.\n        \n    5. Итог: сократил время на сбор отчетов с 2 дней до нескольких часов.\n        \n\n### Сложные и интересные задачи\n\n- Оптимизировал работу ClickHouse, снизив время выполнения аналитических запросов с 3 секунд до 500 мс.\n    \n- Реализовал failover-механику для RabbitMQ, устранив проблему потери сообщений при сбоях серверов.\n    \n- Настроил трассировку запросов через OpenTelemetry, что позволило значительно упростить диагностику сложных цепочек запросов между сервисами.\n\n\n\n\n\n\n\n\n### Факап на работе и вынесенный урок\n\n**Ситуация**  \nВо время работы в **FIX Price** мне поручили задачу по оптимизации ClickHouse, так как аналитические запросы начали выполняться слишком долго, замедляя работу системы отчетности. Я решил ускорить запросы, изменив схему хранения данных и структуру индексов, но не учел, что изменения затронут все существующие отчеты.\n\n**Что пошло не так?**  \nПосле деплоя изменений аналитическая команда обнаружила, что несколько критически важных отчетов начали возвращать некорректные данные. Оказалось, что изменение структуры таблиц привело к несовместимости с ранее написанными SQL-запросами. Из-за этого отчеты показывали неполные данные, и несколько бизнес-решений были приняты на основе неверной информации.\n\n**Как исправили?**\n\n1. **Быстро откатили изменения** — благо, у нас был резервный snapshot базы.\n2. **Проанализировали проблему** — разобрали SQL-запросы аналитиков и выявили несовместимости.\n3. **Согласовали новый формат данных** с аналитиками, чтобы избежать подобных ошибок в будущем.\n4. **Ввели процесс миграционного тестирования** — теперь все изменения в схеме базы проверяются через тестовые отчеты перед релизом.\n5. **Обновили документацию** — подробно описали, как менять схему данных, чтобы избежать несовместимости.\n\n**Вывод и урок**\n\n- **Не стоит менять схему данных без согласования со всеми, кто ее использует.** Важно учитывать влияние даже, казалось бы, локальных изменений на другие команды.\n- **Перед критическими изменениями всегда делать тестовую миграцию и проверять отчеты.** Это помогает заранее выявить проблемы, а не узнавать о них от злых аналитиков.\n- **Хорошая документация и процесс контроля изменений спасают от подобных ошибок в будущем.**\n\nВ результате, после исправлений и корректных миграций, нам удалось не только вернуть стабильность отчетности, но и ускорить выполнение аналитических запросов с 3 секунд до 500 мс."}
	],
	"edges":[]
}