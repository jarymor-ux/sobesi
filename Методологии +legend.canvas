{
  "edges": [
  ],
  "nodes": [
    {
      "height": 1380,
      "id": "8d4e853588b391e2",
      "styleAttributes": {
      },
      "text": "### 1. **Проанализировал медленные запросы и выявил узкие места в индексах и агрегациях**\n\nЧтобы оптимизировать ClickHouse, первым шагом было понимание того, какие именно запросы работают медленно и почему.\n\n#### Что сделал:\n\n- **Использовал команду `EXPLAIN`**  \n    Анализировал план выполнения запросов, чтобы понять, какие части выполняются долго, какие индексы используются и где происходит наибольшая нагрузка.\n    \n    sql\n    \n    КопироватьРедактировать\n    \n    `EXPLAIN PIPELINE SELECT COUNT(*) FROM large_table WHERE event_date > '2024-01-01';`\n    \n    Этот запрос позволяет увидеть, какие стадии выполняются последовательно, где узкие места, и насколько эффективно используется `MergeTree`.\n    \n- **Проверил статистику выполнения запросов**  \n    ClickHouse хранит информацию о медленных запросах в системных таблицах:\n    \n    sql\n    \n    КопироватьРедактировать\n    \n    `SELECT     query,     query_duration_ms,     read_rows,     memory_usage FROM system.query_log WHERE event_date >= today() - 1 ORDER BY query_duration_ms DESC LIMIT 10;`\n    \n    Это помогло выявить самые тяжелые запросы и понять, какие из них требуют оптимизации.\n    \n- **Идентифицировал проблемы с индексами**  \n    Проверил, какие колонки участвуют в фильтрации (`WHERE`), группировке (`GROUP BY`) и сортировке (`ORDER BY`).  \n    В ClickHouse важны первичные индексы (`ORDER BY`) и индексы пропуска (`SKIP INDEX`).\n    \n    sql\n    \n    КопироватьРедактировать\n    \n    `SHOW CREATE TABLE large_table;`\n    \n    Если `ORDER BY` не соответствовал частым фильтрам, то запросы могли сканировать слишком много данных, что замедляло их выполнение.\n    \n\n---\n\n### 2. **Внедрил материализованные представления для предрасчетов популярных запросов**\n\nClickHouse позволяет использовать **Materialized Views**, которые автоматически предрассчитывают результаты запросов и хранят их в таблицах.\n\n#### Проблема:\n\nЗапросы с агрегацией (например, `COUNT`, `SUM`, `AVG`) выполнялись медленно из-за обработки большого объема данных.\n\n#### Решение:\n\nСоздал **материализованное представление** для агрегации данных:\n\nsql\n\nКопироватьРедактировать\n\n`CREATE MATERIALIZED VIEW mv_user_stats ENGINE = AggregatingMergeTree() ORDER BY (user_id) POPULATE AS SELECT     user_id,     count(*) AS total_actions,     sum(revenue) AS total_revenue FROM large_table GROUP BY user_id;`\n\nТеперь запросы на получение общей статистики (`COUNT`, `SUM`) работали в **разы быстрее**, потому что не требовалось сканировать всю исходную таблицу.\n\nТакже использовал **промежуточные материализованные представления** для предрасчетов:\n\nsql\n\nКопироватьРедактировать\n\n`CREATE MATERIALIZED VIEW mv_daily_stats ENGINE = SummingMergeTree() ORDER BY (event_date, user_id) POPULATE AS SELECT     event_date,     user_id,     count(*) AS total_events FROM large_table GROUP BY event_date, user_id;`\n\nТеперь, чтобы получить статистику за определенный день, не нужно было пересчитывать данные — все уже было агрегировано.\n\n---\n\n### 3. **Оптимизировал схему хранения данных, уменьшив дублирование**\n\n#### Проблема:\n\n- Таблица хранила много дублирующихся данных, что увеличивало объем хранимой информации и замедляло запросы.\n\n#### Решение:\n\n- **Изменил схему хранения, убрав избыточные колонки**  \n    Если несколько колонок содержали одни и те же данные в разном формате (например, `timestamp` и `date`), оставил только нужные:\n    \n    sql\n    \n    КопироватьРедактировать\n    \n    `ALTER TABLE large_table DROP COLUMN created_at_string;`\n    \n- **Использовал кодирование и сжатие**  \n    В ClickHouse можно выбирать кодирование колонок:\n    \n    sql\n    \n    КопироватьРедактировать\n    \n    `ALTER TABLE large_table MODIFY COLUMN user_agent CODEC(ZSTD);`\n    \n    Это помогло уменьшить объем хранимых данных и ускорить их обработку.\n    \n- **Применил `LowCardinality` для строковых колонок**  \n    Для колонок с повторяющимися значениями (например, `event_type`) заменил `String` на `LowCardinality(String)`, что ускорило фильтрацию:\n    \n    sql\n    \n    КопироватьРедактировать\n    \n    `ALTER TABLE large_table MODIFY COLUMN event_type LowCardinality(String);`\n    \n- **Использовал `JOIN` вместо дублирования данных**  \n    Вынес редко изменяющуюся информацию в отдельную таблицу, а затем связал через `JOIN`:\n    \n    sql\n    \n    КопироватьРедактировать\n    \n    `CREATE TABLE user_info (     user_id UInt32,     country String ) ENGINE = MergeTree() ORDER BY user_id;`\n    \n    Теперь вместо хранения `country` в `large_table` просто делал `JOIN` при необходимости.\n    \n\n---\n\n### 4. **Итог: снизил время выполнения аналитических запросов с 3 секунд до 500 мс**\n\nПосле оптимизаций время выполнения сложных аналитических запросов уменьшилось **в 6 раз**.\n\n#### Что дало наибольший эффект:\n\n1. **Материализованные представления** — запросы на агрегацию перестали сканировать всю таблицу, что ускорило обработку.\n2. **Оптимизация индексов** — теперь запросы использовали эффективные `ORDER BY`, а `SKIP INDEX` помогли фильтрации.\n3. **Сжатие и кодирование данных** — уменьшился объем хранимых данных, ускорился `I/O`.\n4. **Уменьшение дублирования** — структура базы стала компактнее, ускорились `JOIN`-ы.\n\nТеперь запросы, которые раньше выполнялись **3 секунды**, стали выполняться **за 500 мс**.",
      "type": "text",
      "width": 830,
      "x": -2800,
      "y": -380
    },
    {
      "height": 310,
      "id": "2a0533a2f87f75d1",
      "styleAttributes": {
      },
      "text": "\"как устроен жизненный цикл задачи в вашей команде?\"\n\nвкратце:\n\n1) задачи поступают, кидаются в бэклог\n2) оцениваем их на созвоне методом покера (почитайте что это)\n3) распределяем между разрабами\n4) пишем, отправляем на код ревью\n5) тестинг на стейдже\n6) тестинг на проде",
      "type": "text",
      "width": 560,
      "x": -2250,
      "y": -690
    },
    {
      "height": 900,
      "id": "8fb73e2c4abd8389",
      "styleAttributes": {
      },
      "text": "### **Kanban**\n\n- **Визуализация работы** — задачи отображаются на доске (Backlog → In Progress → Done).\n- **Лимиты WIP (Work In Progress)** — ограничение количества одновременно выполняемых задач.\n- **Поток (Flow)** — непрерывное улучшение процесса, нет фиксированных спринтов.\n- **Гибкость** — задачи можно добавлять/изменять в любой момент.\n\n### **SCRUM**\n\n- **Фиксированные спринты** (обычно 1-4 недели).\n- **Четкие роли** — Product Owner, Scrum Master, Dev Team.\n- **Церемонии** — Daily Standup, Sprint Planning, Sprint Review, Retrospective.\n- **Продуктовый инкремент** — каждый спринт должен давать ценный результат.\n\n### **XP (Extreme Programming)**\n\n- **Частые релизы** — короткие циклы разработки (итерации 1-2 недели).\n- **TDD (Test-Driven Development)** — сначала тесты, потом код.\n- **Парное программирование** — разработчики пишут код вдвоем для лучшего качества.\n- **Простота и рефакторинг** — код должен быть чистым и поддерживаемым.\n- **Непрерывная интеграция** — постоянное объединение кода в репозиторий.",
      "type": "text",
      "width": 460,
      "x": 1580,
      "y": -380
    },
    {
      "height": 1940,
      "id": "9502cdb1b21d31af",
      "styleAttributes": {
      },
      "text": "**М.Видео**\n\n_Golang Developer_\n\n**Ноябрь 2021 — Май 2023**\n\n### Проект\n\nРаботал над backend-сервисами для онлайн-платформы управления заказами. Система была highload, обрабатывала тысячи заказов в сутки с пиковыми нагрузками до 20 000 запросов в день. Основная цель — обеспечение надежности и масштабируемости платформы.\n\n### Команда\n\nВ команде было 8 backend-разработчиков, 4 frontend-разработчика, 3 тестировщика, DevOps-инженер и тимлид. Работа велась в распределенной команде по Scrum, с двухнедельными спринтами, ежедневными дейли-митингами и ретроспективами в конце спринта.\n\n### Основные технологии\n\n- **Базы данных и кеши**: PostgreSQL, Redis, ClickHouse\n- **Очереди**: Kafka, RabbitMQ\n- **API**: REST, gRPC\n- **Контейнеризация и оркестрация**: Docker, Kubernetes\n- **Мониторинг и логирование**: OpenTelemetry, ELK\n- **CI/CD**: GitLab CI/CD\n- **Инфраструктура**: Terraform\n\n### Вклад и достижения\n\n- Разрабатывал backend-сервисы для управления заказами, обеспечивая их надежную работу под высокой нагрузкой.\n- Интегрировал платежные шлюзы и системы лояльности с использованием gRPC и RabbitMQ, что увеличило надежность обработки платежей на 30%.\n- Разработал API для управления программой лояльности, что позволило внедрить персонализированные скидки и бонусы для клиентов, увеличив конверсию использования бонусов на 15%.\n- Внедрил систему мониторинга бизнес-метрик с OpenTelemetry и ELK, что сократило время диагностики сбоев на 40%.\n- Автоматизировал CI/CD пайплайн для деплоя обновлений, сократив время выхода новых релизов с 1 недели до 2 дней.\n\n### Сложные и интересные задачи\n\n- Оптимизировал SQL-запросы в PostgreSQL, что снизило среднее время ответа API с 200 мс до 80 мс.\n- Реализовал механизм дедупликации событий в Kafka, устранив дублирующие сообщения и снизив нагрузку на базу данных на 25%.\n- Настроил балансировку нагрузки на API с помощью Envoy, что позволило повысить отказоустойчивость системы.\n\n### Факап на работе и вынесенный урок (М.Видео)\n\n**Ситуация**\n\nВо время работы в **М.Видео** мне поручили оптимизировать обработку заказов в очереди Kafka. Одна из задач заключалась в снижении нагрузки на базу данных, так как в пиковые часы (например, во время распродаж) количество заказов увеличивалось в несколько раз, и сервис начинал тормозить.\n\nЯ решил добавить механизм **batch-пакетов** — вместо того чтобы писать в базу каждую операцию отдельно, заказы собирались в пакеты и записывались одним большим батчем, что должно было снизить нагрузку на PostgreSQL. Локальные тесты показали хороший результат, и я задеплоил изменения в прод.\n\n**Что пошло не так?**\n\nСпустя час после развертывания начали поступать жалобы: некоторые заказы зависали в статусе «Ожидание оплаты», а клиенты не получали подтверждения. Оказалось, что в реализации батч-записи я не учел один важный момент: если один из заказов в батче был некорректным (например, из-за ошибки в данных), весь батч откатывался.\n\nИз-за этого сотни заказов не сохранялись, а клиенты не получали подтверждения. Кульминацией стала ночь, когда нагрузка резко выросла из-за акции, и тысячи заказов просто зависли. Это привело к финансовым потерям и большому количеству жалоб в поддержку.\n\n**Как исправили?**\n\n1. **Откатили изменения** — вернули старый механизм записи, чтобы остановить сбои.\n2. **Проанализировали проблему** — обнаружили, что из-за отказа одного заказа откатывался весь батч.\n3. **Изменили стратегию обработки ошибок** — теперь при ошибке в одном заказе батч продолжал выполняться, а проблемные заказы записывались в отдельную очередь на разбирательство.\n4. **Добавили автоматический ретрай** — если запись не удалась из-за временной ошибки (например, блокировки таблицы), заказ повторялся с экспоненциальной задержкой.\n5. **Настроили алерты и мониторинг** — теперь если заказы зависали в ожидании, система отправляла предупреждения в Slack, и команда могла быстро реагировать.\n\n**Вывод и урок**\n\n- **Никогда не деплоить критические изменения без полной стратегии отката и мониторинга.**\n- **При работе с батч-обработкой важно учитывать частичный отказ.** Нужно предусмотреть, что один ошибочный элемент не должен ломать весь процесс.\n- **Тестирование на реальных данных важно.** Локальные тесты — это хорошо, но в проде могут всплыть неожиданные сценарии.\n\nПосле исправления логики нам удалось не только предотвратить подобные ошибки в будущем, но и снизить нагрузку на базу на 25%, а время обработки заказов уменьшилось в среднем с 500 мс до 200 мс.",
      "type": "text",
      "width": 680,
      "x": 270,
      "y": -380
    },
    {
      "height": 1160,
      "id": "d6ca9d9b19fb105b",
      "styleAttributes": {
      },
      "text": "### **Kanban**\n\n- **Визуализация работы** — задачи отображаются на **доске Kanban**, которая разделена на колонки (например: **Backlog** → **In Progress** → **Done**).\n    - _Backlog_ — список всех задач, которые нужно выполнить в будущем.\n    - _In Progress_ — задачи, которые сейчас выполняются.\n    - _Done_ — завершённые задачи.\n- **Лимиты WIP (Work In Progress)** — ограничение количества задач, которые могут одновременно выполняться в колонке _In Progress_. Это помогает избежать перегрузки команды.\n- **Поток (Flow)** — работа движется плавно, без жёстких сроков и этапов, в отличие от **SCRUM**.\n- **Гибкость** — задачи можно добавлять, менять и приоритизировать в любой момент.\n\n---\n\n### **SCRUM**\n\n- **Фиксированные спринты** — короткие циклы работы (1-4 недели), в течение которых команда работает над набором задач.\n    - _Спринт_ — фиксированный промежуток времени (обычно 2 недели), за который команда должна выполнить запланированные задачи.\n- **Четкие роли**:\n    - _Product Owner (Владелец продукта)_ — отвечает за **Backlog**, ставит приоритеты и решает, что важно делать в первую очередь.\n    - _Scrum Master_ — помогает команде работать по **SCRUM**, устраняет препятствия и следит за процессом.\n    - _Development Team (Команда разработки)_ — программисты, тестировщики, дизайнеры, которые выполняют задачи.\n- **Церемонии (Scrum Events)** — регулярные встречи:\n    - _Daily Standup_ — короткие 15-минутные встречи команды каждый день, где обсуждают, что было сделано, какие есть проблемы и что планируется сделать.\n    - _Sprint Planning_ — планирование спринта, где выбираются задачи из **Backlog**.\n    - _Sprint Review_ — демонстрация результата работы за спринт.\n    - _Retrospective_ — анализ прошедшего спринта, обсуждение того, что можно улучшить.\n- **Продуктовый инкремент** — после каждого спринта должен быть работающий и улучшенный продукт.\n\n---\n\n### **XP (Extreme Programming)**\n\n- **Частые релизы** — команда выпускает обновления очень часто (раз в 1-2 недели), чтобы быстрее получать обратную связь от пользователей.\n- **TDD (Test-Driven Development)** — разработка через тестирование:\n    - _Программист сначала пишет тест_, который проверяет правильность будущего кода, и только потом пишет сам код.\n- **Парное программирование (Pair Programming)** — два разработчика пишут код вместе за одним компьютером. Один пишет код, другой проверяет, затем они меняются ролями.\n- **Простота и рефакторинг (Refactoring)** — код должен быть чистым, понятным и легко изменяемым.\n    - _Рефакторинг_ — улучшение кода без изменения его функциональности.\n- **Непрерывная интеграция (CI – Continuous Integration)** — все изменения кода сразу добавляются в основную кодовую базу и проходят автоматические тесты, чтобы избежать ошибок.",
      "type": "text",
      "width": 620,
      "x": 950,
      "y": -380
    },
    {
      "height": 2480,
      "id": "a0212027c7844fc7",
      "styleAttributes": {
      },
      "text": "**FIX Price**\n\n_Golang Developer_\n\n**Июнь 2023 — Настоящее время**\n\n### Проект\n\nРазрабатываю highload сервисы для автоматизации процессов ценообразования и управления акциями в сети магазинов. Система ежедневно обрабатывает 5 000 — 10 000 событий, в пиковые дни нагрузка достигает 20 000 событий.\n\n### Команда\n\nВ команде 6 backend-разработчиков, 3 аналитика, 2 DevOps-инженера, 2 тестировщика и тимлид. Работаем по Scrum, с двухнедельными спринтами, ежедневными стендапами и оценкой задач методом покера.\n\n### Основные технологии\n\n- **Базы данных и кеши**: PostgreSQL, Redis, ClickHouse\n- **Очереди**: Kafka, NATS, RabbitMQ\n- **API**: REST, gRPC, WebSockets\n- **Контейнеризация и оркестрация**: Docker, Kubernetes\n- **Мониторинг и логирование**: OpenTelemetry, ELK\n- **CI/CD**: GitLab CI/CD\n- **Сервис-дискавери**: Consul\n\n### Вклад и достижения\n\n- **Разработал алгоритмы динамического ценообразования на основе ClickHouse**:\n    1. Проанализировал текущие модели ценообразования и выявил узкие места.\n    2. Разработал алгоритм, учитывающий спрос, сезонность и конкурентные цены.\n    3. Настроил ETL-процессы для агрегации данных о продажах и динамике цен.\n    4. Оптимизировал запросы в ClickHouse, сократив время обработки на 60%.\n    5. Итог: алгоритм позволил автоматически корректировать цены, повысив маржинальность на 8%.\n- **Реализовал сервис прогнозирования продаж с использованием Kafka и NATS**:\n    1. Проанализировал исторические данные о продажах.\n    2. Реализовал механизм потоковой обработки данных с Kafka и NATS.\n    3. Обучил модель прогнозирования спроса с учетом сезонности и трендов.\n    4. Внедрил автоматизированные оповещения для отдела закупок.\n    5. Итог: улучшено управление закупками, снижены избыточные складские остатки на 12%.\n- **Разработал REST API для интеграции с поставщиками**:\n    1. Определил основные бизнес-процессы и ключевые требования к API.\n    2. Реализовал API с валидацией входных данных и аутентификацией через OAuth2.\n    3. Настроил мониторинг и трассировку запросов через OpenTelemetry.\n    4. Автоматизировал процесс обработки заявок на новые поставки.\n    5. Итог: ускорена обработка заявок на 25%.\n- **Настроил систему мониторинга логистических цепочек с WebSockets**:\n    1. Выявил проблемы в существующей системе логистики.\n    2. Разработал WebSockets-сервис для отслеживания перемещения товаров в реальном времени.\n    3. Внедрил автоматизированные оповещения при задержках в поставках.\n    4. Настроил дашборды с метриками перемещения грузов.\n    5. Итог: сократили время обработки логистических событий на 30%.\n- **Внедрил систему отчетности для маркетинга и продаж с использованием ELK**:\n    1. Систематизировал потребности маркетингового отдела в аналитике.\n    2. Настроил сбор данных через Logstash и индексацию в Elasticsearch.\n    3. Создал дашборды в Kibana с визуализацией ключевых метрик.\n    4. Автоматизировал формирование отчетов по продажам и акциям.\n    5. Итог: сократил время на сбор отчетов с 2 дней до нескольких часов.\n\n### Сложные и интересные задачи\n\n- **Оптимизировал работу ClickHouse**:\n    1. Проанализировал медленные запросы и выявил узкие места в индексах и агрегациях.\n    2. Внедрил материализованные представления для предрасчетов популярных запросов.\n    3. Оптимизировал схему хранения данных, уменьшив дублирование.\n    4. Итог: снизил время выполнения аналитических запросов с 3 секунд до 500 мс.\n- **Реализовал failover-механику для RabbitMQ**:\n    1. Выявил проблему потери сообщений при сбоях одного из серверов в кластере.\n    2. Внедрил кластеризацию и настройку quorum queues для надежности доставки.\n    3. Настроил автоматический retry на уровне продюсера и потребителя.\n    4. Итог: полностью устранил потери сообщений и повысил отказоустойчивость системы.\n- **Настроил трассировку запросов через OpenTelemetry**:\n    1. Добавил распределенный трейсинг в основные сервисы через OpenTelemetry.\n    2. Интегрировал трассировку с ELK и Grafana, настроил визуализацию цепочек запросов.\n    3. Внедрил корелляцию логов и метрик, упростив поиск проблемных мест.\n    4. Итог: время диагностики сложных запросов сократилось на 40%.",
      "type": "text",
      "width": 680,
      "x": -1970,
      "y": -380
    },
    {
      "height": 620,
      "id": "ee137819fafd3d09",
      "styleAttributes": {
      },
      "text": "Как разработчик, я прохожу следующие этапы в рамках спринта:\n\n1. **Планирование спринта**:\n    \n    - Совместно с командой анализируем продуктовый бэклог и определяем цели спринта.\n    - При оценке задач применяется метод покера: каждый участник выставляет оценку сложности, после чего мы приходим к общему мнению по каждой задаче.\n    - Задачи распределяются между участниками, и я получаю задачи, соответствующие моим компетенциям.\n2. **Активная разработка**:\n    \n    - Реализую поставленные задачи, регулярно провожу код-ревью с коллегами и участвую в интеграционных тестированиях.\n    - Ежедневно присутствую на стендапах, где отчитываюсь о прогрессе, обсуждаю возникшие проблемы и корректирую планы при необходимости.\n3. **Демонстрация и ревью**:\n    \n    - По завершении спринта представляем готовый функционал заинтересованным сторонам, собираем обратную связь.\n4. **Ретроспектива**:\n    \n    - Совместно с командой анализируем результаты спринта, обсуждаем, что прошло успешно, а что требует улучшения, и вырабатываем рекомендации для следующих спринтов.\n\nЭта структура позволяет систематически планировать работу, оперативно решать проблемы и повышать эффективность будущих итераций.",
      "type": "text",
      "width": 790,
      "x": -1690,
      "y": -1000
    },
    {
      "height": 2480,
      "id": "6744f7081bdc7148",
      "styleAttributes": {
      },
      "text": "### Общая архитектура проекта\n\n**FIX Price** – высоконагруженное решение для автоматизации процессов динамического ценообразования, прогнозирования продаж, интеграции с поставщиками и мониторинга логистических цепочек в сети магазинов. Система обрабатывает от 5 000 до 10 000 событий ежедневно (в пиковые дни – до 20 000), обеспечивая оперативное обновление цен и улучшение бизнес-показателей.\n\n---\n\n### Микросервисы и их функционал\n\n1. **Микросервис динамического ценообразования**\n    \n    - **Назначение**: Автоматическая корректировка цен с учётом спроса, сезонности и конкурентных цен.\n    - **Основные задачи**:\n        - Анализ существующих моделей ценообразования.\n        - Разработка алгоритмов для динамической коррекции цен.\n        - Настройка ETL-процессов для агрегации данных о продажах.\n        - Оптимизация запросов к ClickHouse (снижение времени обработки на 60%).\n        - Повышение маржинальности на 8%.\n    - **Используемые библиотеки и инструменты**:\n        - Клиент для ClickHouse (например, [mailru/go-clickhouse]).\n        - Библиотеки для работы с PostgreSQL (pgx или go-pg).\n        - Стандартные пакеты для обработки данных и реализации алгоритмов.\n2. **Микросервис прогнозирования продаж**\n    \n    - **Назначение**: Потоковая обработка исторических данных для прогнозирования спроса.\n    - **Основные задачи**:\n        - Сбор и анализ исторических данных о продажах.\n        - Реализация потоковой обработки с использованием Kafka и NATS.\n        - Обучение модели прогнозирования с учётом сезонности и трендов.\n        - Настройка автоматизированных оповещений для отдела закупок.\n        - Снижение избыточных складских остатков на 12%.\n    - **Используемые библиотеки и инструменты**:\n        - [segmentio/kafka-go] для интеграции с Kafka.\n        - [nats-io/nats.go] для работы с NATS.\n        - Стандартные математические и статистические библиотеки Go для обработки данных.\n3. **Микросервис интеграции с поставщиками (REST API)**\n    \n    - **Назначение**: Обеспечение связи с внешними поставщиками через API.\n    - **Основные задачи**:\n        - Анализ бизнес-процессов и определение ключевых требований.\n        - Реализация REST API с валидацией входных данных.\n        - Интеграция аутентификации через OAuth2.\n        - Настройка мониторинга и трассировки запросов (через OpenTelemetry).\n        - Ускорение обработки заявок на 25%.\n    - **Используемые библиотеки и инструменты**:\n        - Фреймворки для роутинга: [gorilla/mux] или [chi].\n        - OAuth2: [golang.org/x/oauth2].\n        - OpenTelemetry для распределенного трейсинга.\n4. **Микросервис мониторинга логистических цепочек**\n    \n    - **Назначение**: Отслеживание перемещения товаров в реальном времени.\n    - **Основные задачи**:\n        - Выявление проблем в существующей логистике.\n        - Реализация сервиса на основе WebSockets для мониторинга перемещения грузов.\n        - Настройка автоматизированных оповещений при задержках.\n        - Построение дашбордов для визуализации метрик.\n        - Сокращение времени обработки логистических событий на 30%.\n    - **Используемые библиотеки и инструменты**:\n        - [gorilla/websocket] для реализации WebSockets.\n        - Интеграция с системами визуализации, например, Grafana.\n5. **Микросервис отчетности для маркетинга и продаж (ELK)**\n    \n    - **Назначение**: Автоматизация формирования и визуализации отчетов.\n    - **Основные задачи**:\n        - Систематизация аналитических требований маркетинга.\n        - Сбор логов через Logstash и их индексация в Elasticsearch.\n        - Создание дашбордов в Kibana.\n        - Автоматизация формирования отчетов, сокращение времени сбора с 2 дней до нескольких часов.\n    - **Используемые библиотеки и инструменты**:\n        - Клиенты для Elasticsearch (например, [olivere/elastic]).\n        - Интеграция с Logstash и Kibana.\n\n---\n\n### Дополнительные системные задачи и оптимизации\n\n6. **Оптимизация ClickHouse**\n    \n    - Анализ медленных запросов, выявление узких мест в индексах и агрегациях.\n    - Внедрение материализованных представлений для предварительных расчётов.\n    - Оптимизация схемы хранения данных для сокращения дублирования.\n    - Результат: время выполнения аналитических запросов сокращено с 3 секунд до 500 мс.\n7. **Реализация failover-механики для RabbitMQ**\n    \n    - Выявление проблемы потери сообщений при сбоях серверов.\n    - Внедрение кластеризации и настройка quorum queues.\n    - Настройка автоматического повторного отправления (retry) для продюсеров и потребителей.\n    - Результат: устранение потерь сообщений и повышение отказоустойчивости.\n8. **Настройка распределенной трассировки (OpenTelemetry)**\n    \n    - Интеграция OpenTelemetry в основные сервисы.\n    - Корреляция логов и метрик, визуализация цепочек запросов через Grafana и ELK.\n    - Результат: сокращение времени диагностики сложных запросов на 40%.\n\n---\n\n### Используемые технологии, библиотеки и инструменты\n\n- **Базы данных и кеши**:\n    \n    - PostgreSQL (библиотеки: pgx, go-pg).\n    - Redis (go-redis).\n    - ClickHouse (mailru/go-clickhouse или аналогичные).\n- **Очереди сообщений**:\n    \n    - Kafka ([segmentio/kafka-go]).\n    - NATS ([nats-io/nats.go]).\n    - RabbitMQ (библиотека [streadway/amqp]).\n- **API и коммуникационные протоколы**:\n    \n    - REST API (роутеры: [gorilla/mux], [chi]).\n    - gRPC (google.golang.org/grpc).\n    - WebSockets ([gorilla/websocket]).\n- **Контейнеризация и оркестрация**:\n    \n    - Docker.\n    - Kubernetes.\n- **Мониторинг и логирование**:\n    \n    - OpenTelemetry для распределенного трейсинга.\n    - ELK Stack (Elasticsearch, Logstash, Kibana).\n    - Grafana для визуализации метрик.\n- **CI/CD и сервис-дискавери**:\n    \n    - GitLab CI/CD.\n    - Consul для обнаружения сервисов.\n\n---\n\n### Обязанности и задачи в проекте\n\n- **Анализ и проектирование**:\n    \n    - Проведение анализа существующих бизнес-процессов ценообразования и логистики.\n    - Выявление узких мест и формирование требований к новым решениям.\n    - Проектирование архитектуры микросервисов с учетом высокой нагрузки.\n- **Разработка и оптимизация**:\n    \n    - Реализация алгоритмов динамического ценообразования с оптимизацией запросов в ClickHouse.\n    - Разработка микросервиса прогнозирования продаж с использованием Kafka и NATS.\n    - Создание и поддержка REST API для интеграции с поставщиками.\n    - Настройка мониторинга логистических цепочек через WebSockets.\n    - Автоматизация формирования отчетов с использованием ELK.\n    - Внедрение failover-механик для RabbitMQ, повышающих отказоустойчивость системы.\n- **Тестирование и развёртывание**:\n    \n    - Написание модульных и интеграционных тестов для проверки корректности работы микросервисов.\n    - Интеграция сервисов в CI/CD пайплайны с использованием GitLab CI/CD.\n    - Взаимодействие с DevOps-командой для развёртывания сервисов в Kubernetes.\n- **Мониторинг и поддержка**:\n    \n    - Настройка OpenTelemetry для распределенного трейсинга и диагностики.\n    - Анализ логов и метрик с использованием ELK и Grafana.\n    - Постоянное улучшение производительности и оперативное реагирование на инциденты.",
      "type": "text",
      "width": 780,
      "x": -1290,
      "y": -380
    },
    {
      "height": 1100,
      "id": "8592e53c2c5672cf",
      "styleAttributes": {
      },
      "text": "### Факап на работе и вынесенный урок\n\n**Ситуация**\n\nВо время работы в **FIX Price** мне поручили задачу по оптимизации ClickHouse, так как аналитические запросы начали выполняться слишком долго, замедляя работу системы отчетности. Я решил ускорить запросы, изменив схему хранения данных и структуру индексов, но не учел, что изменения затронут все существующие отчеты.\n\n**Что пошло не так?**\n\nПосле деплоя изменений аналитическая команда обнаружила, что несколько критически важных отчетов начали возвращать некорректные данные. Оказалось, что изменение структуры таблиц привело к несовместимости с ранее написанными SQL-запросами. Из-за этого отчеты показывали неполные данные, и несколько бизнес-решений были приняты на основе неверной информации.\n\n**Как исправили?**\n\n1. **Быстро откатили изменения** — благо, у нас был резервный snapshot базы.\n2. **Проанализировали проблему** — разобрали SQL-запросы аналитиков и выявили несовместимости.\n3. **Согласовали новый формат данных** с аналитиками, чтобы избежать подобных ошибок в будущем.\n4. **Ввели процесс миграционного тестирования** — теперь все изменения в схеме базы проверяются через тестовые отчеты перед релизом.\n5. **Обновили документацию** — подробно описали, как менять схему данных, чтобы избежать несовместимости.\n\n**Вывод и урок**\n\n- **Не стоит менять схему данных без согласования со всеми, кто ее использует.** Важно учитывать влияние даже, казалось бы, локальных изменений на другие команды.\n- **Перед критическими изменениями всегда делать тестовую миграцию и проверять отчеты.** Это помогает заранее выявить проблемы, а не узнавать о них от злых аналитиков.\n- **Хорошая документация и процесс контроля изменений спасают от подобных ошибок в будущем.**\n\nВ результате, после исправлений и корректных миграций, нам удалось не только вернуть стабильность отчетности, но и ускорить выполнение аналитических запросов с 3 секунд до 500 мс.",
      "type": "text",
      "width": 780,
      "x": -510,
      "y": -380
    }
  ]
}